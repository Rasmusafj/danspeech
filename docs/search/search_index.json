{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"DanSpeech Documentation What is DanSpeech? DanSpeech is an open-source Danish speech recognition (speech-to-text) python package based on the PyTorch deep learning framework. It was developed as part of a Master's thesis at DTU by Martin Carsten Nielsen and Rasmus Arpe Figh Jensen with supervisor Professor Lars Kai. All of the DanSpeech models are end-to-end DeepSpeech 2 models trained on danish text with various data agumentations as an attempt multiply the rather small and public speech recognition data available in Danish. The models perform state-of-the-art speech recognition in Danish but performance is evidently not perfect and conditioned on specific use-cases. Danspeech contains: * An easy-to-use Recognizer that supports different use-cases for Danish speech recognition. * Pre-trained models. * Pre-trained language models. Motivation We believe that speech recognition in Danish should be available for anyone. We therefore developed an open-source and easy-to-use speech recognition system for Danish. An open-source speech recognition system is important to ensure that Danish speech recognition performance will not continue to fall miles behind the performance of English systems. Speech recognition will inevitable be a big part of future IT innovations. Without an easy-to-use and free system, innovation in Danish technologies utilization speech recognition is hindered. The system can be used freely commercially used for companies without the resources to develop their own speech recognition systems or companies who do not wish to outsource speech recognition. The system can also be used as part of education at various universities in Denmark. Performance We benchmarked the system on two Danish benchmarks, namely the public available Nordisk Spr\u00e5kteknologi (NST) dataset and our own (not public due to data gathering restrictions and GDPR) DanSpeech dataset (~1000 noisy recordings). The performance is evaulated in word error rate (WER) Dataset Models Performance NST test DanSpeechPrimary + DSL5Gram (not pruned) LM 12.85% WER DanSpeech dataset TransferLearned + DSL5Gram (not pruned) LM 25.75% WER If you know the specific domain which you wish to apply Danish speech recognition to, and you have either text resources or in the best case speech data available, then you can finetune DanSpeech models to achieve a much better performance for your specific domain than the performance DanSpeech pre-trained models are capable of. See DanSpeech training repository and DanSpeech Demo . DanSpeech training repository If you wish to train your own speech recognition models, or finetune DanSpeech models to your specific domain/use-case, then use the DanSpeech training repository. This requires technical expertise and a GPU. As mentioned above, you can finetune DanSpeech models to achieve a much better performance for your specific domain than the performance DanSpeech pre-trained models are capable of. DanSpeech Demo To test the DanSpeech models on your own audio files or on your own speech, we additionally created a demo that runs as a development django server on localhost. It is easy to install and hence easy to test the models with a GUI (little technical knowledge is required to play around with the demo). The demo also features the finetuned Folketinget DanSpeech model with the finetuned Folketinget language model transcribing a Danish Parliament meeting, which the model was not trained on.","title":"Home"},{"location":"index.html#danspeech-documentation","text":"","title":"DanSpeech Documentation"},{"location":"index.html#what-is-danspeech","text":"DanSpeech is an open-source Danish speech recognition (speech-to-text) python package based on the PyTorch deep learning framework. It was developed as part of a Master's thesis at DTU by Martin Carsten Nielsen and Rasmus Arpe Figh Jensen with supervisor Professor Lars Kai. All of the DanSpeech models are end-to-end DeepSpeech 2 models trained on danish text with various data agumentations as an attempt multiply the rather small and public speech recognition data available in Danish. The models perform state-of-the-art speech recognition in Danish but performance is evidently not perfect and conditioned on specific use-cases. Danspeech contains: * An easy-to-use Recognizer that supports different use-cases for Danish speech recognition. * Pre-trained models. * Pre-trained language models.","title":"What is DanSpeech?"},{"location":"index.html#motivation","text":"We believe that speech recognition in Danish should be available for anyone. We therefore developed an open-source and easy-to-use speech recognition system for Danish. An open-source speech recognition system is important to ensure that Danish speech recognition performance will not continue to fall miles behind the performance of English systems. Speech recognition will inevitable be a big part of future IT innovations. Without an easy-to-use and free system, innovation in Danish technologies utilization speech recognition is hindered. The system can be used freely commercially used for companies without the resources to develop their own speech recognition systems or companies who do not wish to outsource speech recognition. The system can also be used as part of education at various universities in Denmark.","title":"Motivation"},{"location":"index.html#performance","text":"We benchmarked the system on two Danish benchmarks, namely the public available Nordisk Spr\u00e5kteknologi (NST) dataset and our own (not public due to data gathering restrictions and GDPR) DanSpeech dataset (~1000 noisy recordings). The performance is evaulated in word error rate (WER) Dataset Models Performance NST test DanSpeechPrimary + DSL5Gram (not pruned) LM 12.85% WER DanSpeech dataset TransferLearned + DSL5Gram (not pruned) LM 25.75% WER If you know the specific domain which you wish to apply Danish speech recognition to, and you have either text resources or in the best case speech data available, then you can finetune DanSpeech models to achieve a much better performance for your specific domain than the performance DanSpeech pre-trained models are capable of. See DanSpeech training repository and DanSpeech Demo .","title":"Performance"},{"location":"index.html#danspeech-training-repository","text":"If you wish to train your own speech recognition models, or finetune DanSpeech models to your specific domain/use-case, then use the DanSpeech training repository. This requires technical expertise and a GPU. As mentioned above, you can finetune DanSpeech models to achieve a much better performance for your specific domain than the performance DanSpeech pre-trained models are capable of.","title":"DanSpeech training repository"},{"location":"index.html#danspeech-demo","text":"To test the DanSpeech models on your own audio files or on your own speech, we additionally created a demo that runs as a development django server on localhost. It is easy to install and hence easy to test the models with a GUI (little technical knowledge is required to play around with the demo). The demo also features the finetuned Folketinget DanSpeech model with the finetuned Folketinget language model transcribing a Danish Parliament meeting, which the model was not trained on.","title":"DanSpeech Demo"},{"location":"installing.html","text":"DanSpeech Installation Currently DanSpeech is installed by $ git clone https://github.com/Rasmusafj/danspeech $ cd danspeech $ pip install . -r requirements.txt DanSpeech requires python 3.5+","title":"Installation"},{"location":"installing.html#danspeech-installation","text":"Currently DanSpeech is installed by $ git clone https://github.com/Rasmusafj/danspeech $ cd danspeech $ pip install . -r requirements.txt DanSpeech requires python 3.5+","title":"DanSpeech Installation"},{"location":"lms.html","text":"","title":"Pre-trained language models"},{"location":"models.html","text":"","title":"Pre-trained DS models"},{"location":"recognizer.html","text":"","title":"Recognizer"},{"location":"usage.html","text":"Usage import danspeech from danspeech.pretrained_models import TestModel from danspeech.language_models import DSL3gram from danspeech.audio import load_audio # Load a DanSpeech model. If the model does not exists, it will be downloaded. model = TestModel () recognizer = danspeech . Recognizer ( model = model ) # Load the audio file. audio = load_audio ( path = \"./example_files/u0013002.wav\" ) print ( recognizer . recognize ( audio )) # DanSpeech with a language model. # Note: Requires ctcdecode to work! lm = DSL3gram () recognizer . update_decoder ( lm = lm , alpha = 1.3 , beta = 0.15 , beam_width = 32 ) print ( recognizer . recognize ( audio , show_all = False ))","title":"Usage"},{"location":"usage.html#usage","text":"import danspeech from danspeech.pretrained_models import TestModel from danspeech.language_models import DSL3gram from danspeech.audio import load_audio # Load a DanSpeech model. If the model does not exists, it will be downloaded. model = TestModel () recognizer = danspeech . Recognizer ( model = model ) # Load the audio file. audio = load_audio ( path = \"./example_files/u0013002.wav\" ) print ( recognizer . recognize ( audio )) # DanSpeech with a language model. # Note: Requires ctcdecode to work! lm = DSL3gram () recognizer . update_decoder ( lm = lm , alpha = 1.3 , beta = 0.15 , beam_width = 32 ) print ( recognizer . recognize ( audio , show_all = False ))","title":"Usage"}]}