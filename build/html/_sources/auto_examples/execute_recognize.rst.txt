.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_examples_execute_recognize.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_execute_recognize.py:


Transcribing a single audio file
================================

In this example script, DanSpeech is used to transcribe the same audio files with three different methods:

- **greedy decoding** - using no external language model
- **Beam search decoding** - Decoding with a language model (´´DSL3Gram´´)
- **Beam search decoding (all beams)** - Decoding with a language model (´´DSL3Gram´´) and returning
    the ´´beam_width´´ most probable beams




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Using device: cpu
    DanSpeech model updated to: TestModel

    No language model:
    tester en to tre fire sem seks syv otte
    DanSpeech decoder updated 

    Single transcription:
    tester en to tre fire fem seks syv otte

    Most likely beams:
    tester en to tre fire fem seks syv otte
    tester en to tre fire fem seks syv ofte
    tester en to tre fire fem seks syv otter
    tester en to tre fire fem seks syv tte
    tester en to tre fire fem seks syv ottey
    tester en to tre fire fem seks syv ote
    tester en to tre fire fem seks syv ottet
    tester en to tre fire fem seks syv ottek
    tester en to tre fire fem seks syv ottes
    tester en to tre fire fem seks syv otteo





|


.. code-block:: default


    from danspeech import Recognizer
    from danspeech.pretrained_models import TestModel
    from danspeech.language_models import DSL3gram
    from danspeech.audio import load_audio

    # Load a DanSpeech model. If the model does not exists, it will be downloaded.
    model = TestModel()
    recognizer = Recognizer(model=model)

    # Load the audio file.
    audio = load_audio(path="../example_files/u0013002.wav")

    print()
    print("No language model:")
    print(recognizer.recognize(audio))

    # DanSpeech with a language model.
    # Note: Requires ctcdecode to work!
    lm = DSL3gram()
    recognizer.update_decoder(lm=lm, alpha=1.2, beta=0.15, beam_width=10)

    print()
    print("Single transcription:")
    print(recognizer.recognize(audio, show_all=False))

    print()
    beams = recognizer.recognize(audio, show_all=True)
    print("Most likely beams:")
    for beam in beams:
        print(beam)


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  17.274 seconds)


.. _sphx_glr_download_auto_examples_execute_recognize.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: execute_recognize.py <execute_recognize.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: execute_recognize.ipynb <execute_recognize.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
